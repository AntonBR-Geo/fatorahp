# app.py
import streamlit as st
import pandas as pd
import numpy as np
import io, csv, re
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(page_title="AHP App ‚Äî Robusto", layout="wide")

# =========================================================
# Cabe√ßalho e tutorial
# =========================================================
st.title("üìä FatorAHP ‚Äî Analisador de Fatores e Pesos com AHP")
st.markdown("""
### üìù Como usar este aplicativo

1. **Carregue o arquivo CSV** contendo **apenas os fatores num√©ricos** que deseja analisar  
   - O arquivo deve conter:  
     - Primeira linha = nomes das vari√°veis (ex: `Fator1;Fator2;Fator3`).  
     - Demais linhas = valores num√©ricos.  
   - ‚ö†Ô∏è N√£o inclua colunas de identifica√ß√£o, nomes ou c√≥digos ‚Äî apenas os fatores.

2. **Estat√≠sticas Descritivas**  
   - O app calcula m√©dia, desvio padr√£o, coeficiente de varia√ß√£o (CV), quartis, etc.

3. **Histogramas com densidade**  
   - Para verificar a distribui√ß√£o de cada fator (simetria, outliers, modas).

4. **Matriz AHP**  
   - Use a sugest√£o autom√°tica (baseada em m√©dia + CV) ou preencha manualmente.  
   - No modo manual, edite apenas o tri√¢ngulo superior ‚Äî os inversos s√£o preenchidos automaticamente.

5. **C√°lculo final**  
   - O app exibe os pesos dos fatores, Œªm√°x, CI e CR.  
   - Tamb√©m mostra um ranking com classifica√ß√£o da import√¢ncia (Muito Alta, Alta, M√©dia, Baixa).

---
""")

# -------------------------
# Utilit√°rios para leitura do CSV (robusto)
# -------------------------
def try_decode(raw_bytes):
    for enc in ('utf-8', 'latin1', 'cp1252'):
        try:
            s = raw_bytes.decode(enc)
            return s, enc
        except Exception:
            continue
    return raw_bytes.decode('utf-8', errors='replace'), 'utf-8'

def read_csv_flexible(uploaded_file):
    uploaded_file.seek(0)
    raw = uploaded_file.read()
    text, encoding = try_decode(raw)

    # Tentativas comuns: (sep, decimal)
    attempts = [
        (';', ','),   # comum em BR: ; e decimal v√≠rgula
        (',', '.'),   # csv padr√£o en/us
        ('\t', '.'),  # tsv
        ('|', '.'),
    ]

    for sep, decimal in attempts:
        try:
            df = pd.read_csv(io.StringIO(text), sep=sep, decimal=decimal, engine='python')
            # se resultou mais de 1 coluna plaus√≠vel -> sucesso
            if df.shape[1] > 1:
                return df, sep, decimal, encoding
            # se apenas uma coluna, pode ainda estar correto (um campo apenas)
        except Exception:
            pass

    # Tentar csv.Sniffer (pode falhar quando h√° v√≠rgulas decimais)
    try:
        dialect = csv.Sniffer().sniff(text[:4096], delimiters=[',',';','\t','|'])
        sep = dialect.delimiter
        # tentar duas op√ß√µes de decimal
        for decimal in [',', '.']:
            try:
                df = pd.read_csv(io.StringIO(text), sep=sep, decimal=decimal, engine='python')
                if df.shape[1] > 1:
                    return df, sep, decimal, encoding
            except Exception:
                pass
    except Exception:
        pass

    # fallback: se √© uma √∫nica coluna com delimitadores dentro das linhas, split manualmente
    lines = [ln for ln in text.splitlines() if ln.strip()!='']
    if len(lines) > 0:
        # detecta separador mais frequente nas linhas
        counts = {d: sum(ln.count(d) for ln in lines[:20]) for d in [';', ',', '\t', '|']}
        sep = max(counts, key=counts.get)
        # split
        rows = [re.split(r'[;,\t|]', ln) for ln in lines]
        header = rows[0]
        data = rows[1:]
        df = pd.DataFrame(data, columns=header)
        # assumimos decimal = ',' se sep == ';' (heur√≠stica)
        decimal = ',' if sep == ';' else '.'
        return df, sep, decimal, encoding

    # √∫ltima tentativa: usar pandas autodetect
    try:
        uploaded_file.seek(0)
        df = pd.read_csv(uploaded_file, engine='python')
        return df, ',', '.', encoding
    except Exception as e:
        raise ValueError(f"N√£o foi poss√≠vel ler o CSV automaticamente: {e}")

def clean_and_convert(df, decimal_hint):
    df = df.copy()
    # limpar nomes
    df.columns = [str(c).strip() for c in df.columns]
    for c in df.columns:
        s = df[c].astype(str).str.strip()
        s = s.str.replace(r'(^"|"$)', '', regex=True)  # remove aspas extremas
        s = s.str.replace(r'\s+', '', regex=True)      # remove espa√ßos
        # se decimal_hint for ',' tratamos poss√≠veis milhares com '.' e v√≠rgula como decimal
        if decimal_hint == ',':
            # remover pontos que atuam como separador de milhares (heur√≠stica)
            # somente se existirem padr√µes como \d.\d{3}
            s = s.str.replace(r'\.(?=\d{3}(?:[\.\,]|$))', '', regex=True)
            s = s.str.replace(',', '.')
        else:
            # remove v√≠rgulas como separador de milhares
            s = s.str.replace(',', '', regex=True)
        df[c] = pd.to_numeric(s, errors='coerce')
    # drop colunas completamente nulas
    df = df.loc[:, df.notna().any(axis=0)]
    return df

# -------------------------
# AHP: gerar matriz a partir da heur√≠stica (dist√¢ncia m√©dia a 1)
# -------------------------
def gerar_matriz_sugestao(df_norm):
    # df_norm: DataFrame num√©rico (de prefer√™ncia normalizado m√©dia=1)
    distancias = df_norm.apply(lambda col: np.nanmean(np.abs(col - 1)), axis=0).to_dict()
    # ordenar por menor dist√¢ncia (maior prioridade)
    ordenado = sorted(distancias.items(), key=lambda x: x[1])
    variaveis = [v for v,_ in ordenado]
    n = len(variaveis)
    # scores inteiros: 1¬∫ -> n, 2¬∫ -> n-1, ..., √∫ltimo -> 1
    scores_int = {variaveis[i]: n - i for i in range(n)}
    # construir matriz (usar raz√£o de scores e arredondar para inteiro Saaty)
    matriz = np.ones((n,n), dtype=float)
    for i in range(n):
        for j in range(i+1, n):
            ratio = scores_int[variaveis[i]] / scores_int[variaveis[j]]
            ratio_r = int(round(ratio))
            ratio_r = min(max(ratio_r, 1), 9)
            matriz[i,j] = ratio_r
            matriz[j,i] = 1.0 / ratio_r
    df_scores = pd.DataFrame({
        "Vari√°vel": variaveis,
        "Dist√¢ncia M√©dia a 1": [distancias[v] for v in variaveis],
        "Score (inteiro)": [scores_int[v] for v in variaveis]
    })
    matriz_df = pd.DataFrame(matriz, index=variaveis, columns=variaveis)
    return matriz_df, df_scores

# -------------------------
# AHP: c√°lculo de pesos e √≠ndices
# -------------------------
def calcular_ahp_indices(A):
    # A deve ser matriz quadrada, rec√≠proca (ou quase)
    A = np.array(A, dtype=float)
    n = A.shape[0]
    # Normaliza√ß√£o por coluna e m√©dia das linhas (m√©todo de m√©dia - fallback)
    with np.errstate(divide='ignore', invalid='ignore'):
        col_sums = A.sum(axis=0)
        matriz_norm = A / col_sums
        pesos_rowmean = np.nanmean(matriz_norm, axis=1)
    # M√©todo de autovetor (mais preciso)
    try:
        autovalores, autovetores = np.linalg.eig(A)
        # escolher autovalor com maior parte real
        index_max = np.argmax(autovalores.real)
        lambda_max = autovalores[index_max].real
        vetor = autovetores[:, index_max].real
        pesos = np.abs(vetor)
        if pesos.sum() == 0:
            pesos = pesos_rowmean
        else:
            pesos = pesos / pesos.sum()
    except Exception:
        # fallback
        pesos = pesos_rowmean
        lambda_max = np.nan

    # CI e CR
    CI = (lambda_max - n) / (n - 1) if n > 1 and not np.isnan(lambda_max) else 0.0
    RI_table = {1:0.00,2:0.00,3:0.58,4:0.90,5:1.12,6:1.24,7:1.32,8:1.41,9:1.45,10:1.49}
    RI = RI_table.get(n, 1.49)
    CR = CI / RI if RI > 0 else 0.0
    return pesos, lambda_max, CI, CR

# -------------------------
# Fun√ß√£o: aplica reciprocidade/valida escala Saaty a partir da matriz editada
# -------------------------
def enforce_reciprocity_and_scale(df_matrix):
    M = df_matrix.copy().astype(float).values
    n = M.shape[0]
    # garantir diagonal 1
    for i in range(n):
        M[i,i] = 1.0
    # para cada par i<j, decidir valor principal e aplicar inverso
    for i in range(n):
        for j in range(i+1, n):
            aij = M[i,j]
            aji = M[j,i]
            # se aij √© nan ou zero, mas aji existe -> usar aji
            if not np.isfinite(aij) or aij == 0:
                if np.isfinite(aji) and aji != 0:
                    val = float(aji)
                    # se usu√°rio preencheu menor que 1 assume que foi inverso ent√£o invert
                    if val < 1:
                        val = 1.0 / val
                    # clamp 1..9
                    val = min(max(val, 1.0), 9.0)
                    M[i,j] = val
                    M[j,i] = 1.0 / val
                else:
                    # nenhum valor fornecido -> assume 1
                    M[i,j] = 1.0
                    M[j,i] = 1.0
            else:
                val = float(aij)
                # se o usu√°rio digitar um valor <1 no tri√¢ngulo superior, interpretamos como inverso
                if val < 1:
                    val = 1.0 / val
                val = min(max(val, 1.0), 9.0)
                M[i,j] = val
                M[j,i] = 1.0 / val
    return pd.DataFrame(M, index=df_matrix.index, columns=df_matrix.columns)

# -------------------------
# UI e fluxo principal
# -------------------------
st.sidebar.header("Upload & Config")
uploaded = st.sidebar.file_uploader("Carregar CSV (sep: ; ou , ou \\t)", type=['csv', 'txt'])

if uploaded is not None:
    try:
        df_raw, detected_sep, detected_decimal, encoding = read_csv_flexible(uploaded)
    except Exception as e:
        st.error(f"Erro ao ler o arquivo automaticamente: {e}")
        st.stop()

    st.markdown("### üóÇÔ∏è Dados carregados (preview)")
    st.write(f"**Detectado:** separador = `{detected_sep}`, decimal_hint = `{detected_decimal}`, encoding = `{encoding}`")
    st.dataframe(df_raw.head(8))

    # convers√£o
    df_clean = clean_and_convert(df_raw, detected_decimal)
    if df_clean.shape[1] == 0:
        st.error("N√£o foram detectadas colunas num√©ricas ap√≥s a convers√£o. Verifique o separador/decimal do arquivo.")
        st.stop()

    st.markdown("### üìà Estat√≠sticas Descritivas (ap√≥s convers√£o para num√©rico)")
    st.write(df_clean.describe().T)

    # op√ß√£o de normalizar (m√©dia = 1)
    big_means = (df_clean.mean().abs() > 10).any()
    if big_means:
        st.warning("Algumas vari√°veis t√™m m√©dia muito alta ‚Äî normalizar para m√©dia = 1 √© recomendado para a heur√≠stica.")
    normalizar = st.checkbox("Normalizar vari√°veis para m√©dia = 1 (recomendado)", value=True)

    if normalizar:
        means = df_clean.mean().replace(0, np.nan)
        df_norm = df_clean.divide(means, axis=1).fillna(0)
    else:
        df_norm = df_clean.copy()

    st.markdown("### üîé Preview (dados usados para calcular Dist√¢ncia M√©dia a 1)")
    st.dataframe(df_norm.head(8))

    # ---------- NOVO: histogramas COM DENSIDADE (antes do Passo 3) ----------
    st.markdown("### üìä Visualiza√ß√£o de Histograma com Densidade")
    st.caption("O histograma ajuda a identificar assimetrias, m√∫ltiplas modas e outliers ‚Äî barras azuis (frequ√™ncia/densidade) e linha vermelha (densidade).")

    cols = st.columns(3)
    for i, col in enumerate(df_norm.columns):
        fig, ax = plt.subplots(figsize=(6, 3.5))
        try:
            sns.histplot(df_norm[col].dropna(), bins=20, stat="density", color="skyblue", alpha=0.7, ax=ax)
        except Exception:
            ax.hist(df_norm[col].dropna(), bins=20, density=True, alpha=0.6)
        try:
            sns.kdeplot(df_norm[col].dropna(), color="red", ax=ax, linewidth=2)
        except Exception:
            pass
        ax.set_title(f"Histograma e Curva de Densidade de {col}")
        ax.set_xlabel(col)
        ax.set_ylabel("Densidade")
        with cols[i % 3]:
            st.pyplot(fig)
    # -----------------------------------------------------------------------

    # gerar sugest√£o
    matriz_sugerida, tabela_scores = gerar_matriz_sugestao(df_norm)
    st.markdown("### üéØ Passo 3: Tabela de Pontua√ß√µes (base da sugest√£o AHP)")
    st.dataframe(tabela_scores)

    # escolha entre sugest√£o edit√°vel ou preencher manualmente
    st.markdown("---")
    st.markdown("### üßÆ Passo 4: Matriz de Compara√ß√£o Pareada (Sugest√£o ou Manual)")
    modo = st.radio("Modo de preenchimento:", ["Usar Sugest√£o Autom√°tica", "Preencher Manualmente"], horizontal=True)

    variaveis = matriz_sugerida.index.tolist()
    n = len(variaveis)

    if modo == "Usar Sugest√£o Autom√°tica":
        st.info("Matriz sugerida (voc√™ pode editar os valores). Preferencialmente edite somente o tri√¢ngulo superior; o sistema ajustar√° os inversos ao calcular.")
        try:
            # nova API
            edited = None
            try:
                edited = st.data_editor(matriz_sugerida, num_rows="fixed", use_container_width=True)
            except Exception:
                edited = st.experimental_data_editor(matriz_sugerida, num_rows="fixed", use_container_width=True)
            matriz_editada = edited.copy()
        except Exception:
            st.warning("Editor interativo n√£o dispon√≠vel ‚Äî exibindo apenas a sugest√£o.")
            st.dataframe(matriz_sugerida)
            matriz_editada = matriz_sugerida.copy()
    else:
        st.info("Preencha manualmente os valores **apenas no tri√¢ngulo superior** (acima da diagonal). "
                "Os valores da parte inferior ser√£o preenchidos automaticamente com os inversos.")

        matriz_manual = pd.DataFrame(np.eye(n), index=variaveis, columns=variaveis)

        try:
            edited = None
            try:
                edited = st.data_editor(matriz_manual, num_rows="fixed", use_container_width=True)
            except Exception:
                edited = st.experimental_data_editor(matriz_manual, num_rows="fixed", use_container_width=True)

            # aplicar reciprocidade logo ap√≥s edi√ß√£o
            matriz_editada = enforce_reciprocity_and_scale(edited.copy())

            st.subheader("Matriz (com inversos aplicados automaticamente)")
            st.dataframe(matriz_editada.style.format("{:.4f}"))

        except Exception:
            st.warning("Editor interativo n√£o dispon√≠vel ‚Äî exibindo matriz identidade.")
            st.dataframe(matriz_manual)
            matriz_editada = matriz_manual.copy()
    
    # guardamos matriz editada na sess√£o
    st.session_state['matriz_editada'] = matriz_editada

    st.markdown("---")
    st.markdown("### üìå Passo 5: C√°lculo e Resultados do AHP")

    if st.button("Calcular AHP"):
        try:
            matriz_ed = st.session_state.get('matriz_editada').copy()
            # converter tudo para num√©rico
            for c in matriz_ed.columns:
                matriz_ed[c] = pd.to_numeric(matriz_ed[c], errors='coerce')

            # aplicar reciprocidade e escala Saaty
            matriz_final = enforce_reciprocity_and_scale(matriz_ed)

            # calcular √≠ndices e pesos
            pesos, lambda_max, CI, CR = calcular_ahp_indices(matriz_final.values)
            pesos = np.array(pesos, dtype=float)
            if pesos.sum() == 0:
                st.error("Erro: pesos calculados como zeros. Verifique os valores da matriz.")
                st.stop()
            pesos_pct = (pesos / pesos.sum()) * 100

            # exibir matriz final
            st.subheader("üî¢ Matriz Pareada Final (reciprocidade aplicada)")
            st.dataframe(matriz_final.style.format("{:.4f}"))

            # exibir pesos e ranking
            df_pesos = pd.DataFrame({
                "Vari√°vel": matriz_final.index,
                "Peso (valor)": pesos,
                "Import√¢ncia (%)": pesos_pct
            }).sort_values("Import√¢ncia (%)", ascending=False).reset_index(drop=True)
            df_pesos["Classifica√ß√£o"] = df_pesos["Import√¢ncia (%)"].apply(
                lambda p: "üü¢ Muito Alta" if p >= 30 else ("üü° Alta" if p >= 20 else ("üîµ M√©dia" if p >= 10 else "üî¥ Baixa"))
            )

            st.subheader("üìä Pesos dos Crit√©rios e Classifica√ß√£o")
            st.dataframe(df_pesos.style.format({"Import√¢ncia (%)":"{:.2f}", "Peso (valor)":"{:.6f}"}))

            # exibir √≠ndices de consist√™ncia
            st.subheader("üìè √çndices de Consist√™ncia")
            st.write(f"- Œªm√°x (autovalor m√°ximo): **{lambda_max:.6f}**")
            st.write(f"- CI (√çndice de Consist√™ncia): **{CI:.6f}**")
            st.write(f"- CR (Raz√£o de Consist√™ncia): **{CR:.6f}**")
            if CR < 0.1:
                st.success("‚úÖ Matriz consistente ‚Äî julgamentos s√£o l√≥gicos.")
            else:
                st.error("‚ö†Ô∏è Matriz inconsistente ‚Äî revise seus julgamentos!")

            # bot√£o de download
            csv_bytes = df_pesos.to_csv(index=False).encode('utf-8')
            st.download_button("‚¨áÔ∏è Baixar Pesos (CSV)", data=csv_bytes, file_name="ahp_pesos.csv", mime="text/csv")

        except Exception as e:
            st.error(f"Erro no c√°lculo do AHP: {e}")

else:
    st.info("Carregue um CSV no sidebar. Dica: arquivos gerados no Brasil frequentemente usam `;` e `,` como decimal.")
